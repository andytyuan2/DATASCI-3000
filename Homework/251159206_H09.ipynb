{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WorgMA_E_iHU"
      },
      "source": [
        "# Assignment 9: CNN with CIFAR-10\n",
        "\n",
        "## Introduction:\n",
        "In this coursework, you will gain practical experience using Convolutional Neural Networks (CNNs) for image classification. Specifically, you'll use two widely recognized pre-trained architectures—VGG16 and ResNet18—to classify images from the CIFAR-10 dataset. CIFAR-10 consists of 60,000 color images (32x32 pixels), evenly divided across 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck.\n",
        "\n",
        "You'll apply transfer learning by adapting these pre-trained models to the CIFAR-10 dataset, train and evaluate both models, compare their performance.\n",
        "\n",
        "## Objectives:\n",
        "- Understand and implement transfer learning.\n",
        "- Train CNN models using pre-trained architectures.\n",
        "- Unfreeze and fine-tune the final convolutional layer of each model.\n",
        "- Evaluate and compare the performance of different CNN models.\n",
        "- Analyze results with a confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6kSc0h8_iHX"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms.v2 as v2\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.models import VGG16_Weights, ResNet18_Weights, vgg16, resnet18\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import Subset, DataLoader, random_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import seaborn as sns\n",
        "import torch_directml\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZmKokh4_iHY"
      },
      "outputs": [],
      "source": [
        "# Check if GPU (CUDA) is available, else use CPU\n",
        "print(f\"Is GPU Acceleration supported by this system? {torch_directml.is_available()}\")\n",
        "dml_device = torch_directml.device()\n",
        "print(f\"Using DirectML device: {dml_device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oD56KzON_iHY"
      },
      "source": [
        "## Question 1: Dataset Setup and Exploration\n",
        "1. Download and load the CIFAR-10 dataset using `torchvision.datasets.CIFAR10`.\n",
        "2. Apply model-specific transformations with data augmentation:\n",
        "   - For VGG16: Use transformations from `VGG16_Weights.DEFAULT.transforms` as a base and apply additional augmentations:\n",
        "       - `AutoAugment` with CIFAR10 policy\n",
        "       - `RandomHorizontalFlip` (50% chance)\n",
        "   - For ResNet18: Use `ResNet18_Weights.DEFAULT.transforms` similarly with the same augmentations applied.\n",
        "3. Use 10% of the training and testing datasets to reduce computation time.\n",
        "4. Define DataLoaders separately for each model for efficient and correct training/testing behavior. Ensure `shuffle = True` for training DataLoaders.\n",
        "5. Visualize a batch of sample images from each model’s DataLoader to confirm that preprocessing and augmentations have been applied correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEoecQEv_iHZ"
      },
      "outputs": [],
      "source": [
        "# load data\n",
        "\n",
        "vgg_base_transforms = VGG16_Weights.DEFAULT.transforms()\n",
        "resnet_base_transforms = ResNet18_Weights.DEFAULT.transforms()\n",
        "\n",
        "vgg_transform = transforms.Compose([\n",
        "    v2.AutoAugment(policy=v2.AutoAugmentPolicy.CIFAR10),\n",
        "    v2.RandomHorizontalFlip(p=0.5),\n",
        "    vgg_base_transforms,\n",
        "])\n",
        "\n",
        "resnet_transform = transforms.Compose([\n",
        "    v2.AutoAugment(policy=v2.AutoAugmentPolicy.CIFAR10),\n",
        "    v2.RandomHorizontalFlip(p=0.5),\n",
        "    resnet_base_transforms,\n",
        "])\n",
        "\n",
        "# Loading data\n",
        "full_train_vgg = torchvision.datasets.CIFAR10(root='./data',\n",
        "                                              train=True,\n",
        "                                              download=True,\n",
        "                                              transform=vgg_transform)\n",
        "full_test_vgg = torchvision.datasets.CIFAR10(root='./data',\n",
        "                                             train=False,\n",
        "                                             download=True,\n",
        "                                             transform=vgg_transform)\n",
        "\n",
        "full_train_resnet = torchvision.datasets.CIFAR10(root='./data',\n",
        "                                                 train=True,\n",
        "                                                 download=True,\n",
        "                                                 transform=resnet_transform)\n",
        "full_test_resnet = torchvision.datasets.CIFAR10(root='./data',\n",
        "                                                train=False,\n",
        "                                                download=True,\n",
        "                                                transform=resnet_transform)\n",
        "\n",
        "# Use 10% of data\n",
        "train_size = int(0.1 * len(full_train_vgg))\n",
        "test_size = int(0.1 * len(full_test_vgg))\n",
        "\n",
        "train_subset_vgg, _ = torch.utils.data.random_split(full_train_vgg,\n",
        " [train_size, len(full_train_vgg) - train_size])\n",
        "test_subset_vgg, _ = torch.utils.data.random_split(full_test_vgg,\n",
        " [test_size, len(full_test_vgg) - test_size])\n",
        "\n",
        "train_subset_resnet, _ = torch.utils.data.random_split(full_train_resnet,\n",
        " [train_size, len(full_train_resnet) - train_size])\n",
        "test_subset_resnet, _ = torch.utils.data.random_split(full_test_resnet,\n",
        " [test_size, len(full_test_resnet) - test_size])\n",
        "\n",
        "# DataLoader\n",
        "train_loader_vgg = DataLoader(train_subset_vgg, batch_size=64, shuffle=True)\n",
        "test_loader_vgg = DataLoader(test_subset_vgg, batch_size=64, shuffle=False)\n",
        "\n",
        "train_loader_resnet = DataLoader(train_subset_resnet, batch_size=64, shuffle=True)\n",
        "test_loader_resnet = DataLoader(test_subset_resnet, batch_size=64, shuffle=False)\n",
        "\n",
        "# Load your models and move them to the device\n",
        "vgg_model = vgg16(weights=VGG16_Weights.DEFAULT).to(dml_device)\n",
        "resnet_model = resnet18(weights=ResNet18_Weights.DEFAULT).to(dml_device)\n",
        "\n",
        "# Verify transforms by visualizing VGG16-prepared images\n",
        "def show_batch(loader, title):\n",
        "    images, labels = next(iter(loader))\n",
        "    img_grid = torchvision.utils.make_grid(images[:8], nrow=4)\n",
        "    npimg = img_grid.numpy()\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.title(title)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "show_batch(train_loader_vgg, \"VGG16 Augmented CIFAR-10 Samples\")\n",
        "show_batch(train_loader_resnet, \"ResNet18 Augmented CIFAR-10 Samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoA_Dj-D_iHZ"
      },
      "source": [
        "Examine the CIFAR-10 images after applying transformations. Identify two classes you believe are most difficult for the models to distinguish and explain why."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ueehy-J_iHZ"
      },
      "source": [
        "**Written Answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsOORCZH_iHZ"
      },
      "source": [
        "## Question 2: Model Definitions – VGG16 and ResNet18\n",
        "1. Load pre-trained VGG16 and ResNet18 models from torchvision.\n",
        "2. Freeze all convolutional layers initially, then unfreeze the last convolutional block in both models.\n",
        "3. Modify the classifier layers to accommodate CIFAR-10 classification (10 output classes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCy3711T_iHa"
      },
      "outputs": [],
      "source": [
        "# VGG16 setup\n",
        "vgg16 = models.vgg16(weights = models.VGG16_Weights.DEFAULT)\n",
        "\n",
        "for param in vgg16.features.parameters(): # freeze\n",
        "    param.requires_grad = False\n",
        "for param in vgg16.features[24:].parameters(): # unfreeze\n",
        "    param.requires_grad = True\n",
        "\n",
        "vgg16.classifier[6] = nn.Linear(4096, 10)\n",
        "vgg16_model = vgg16.to(dml_device)\n",
        "\n",
        "\n",
        "# ResNet18 setup\n",
        "resnet18 = models.resnet18(weights = models.ResNet18_Weights.DEFAULT)\n",
        "\n",
        "for param in resnet18.parameters(): # freeze\n",
        "    param.requires_grad = False\n",
        "for param in resnet18.layer4.parameters(): # unfreeze\n",
        "    param.requires_grad = True\n",
        "\n",
        "resnet18.fc = nn.Linear(resnet18.fc.in_features, 10)\n",
        "resnet18_model = resnet18.to(dml_device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8IhJC0v1sRo"
      },
      "source": [
        "Explain the concept of transfer learning and its specific advantages when applied to CIFAR-10 classification using models like VGG16 and ResNet18."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjOIzSkW1sRo"
      },
      "source": [
        "**Written Answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ME7xu-z_iHa"
      },
      "source": [
        "## Question 3: Training the Models\n",
        "1. Define the loss function (Cross-Entropy Loss).\n",
        "2. Initialize Adam optimizers for each model with a learning rate of 0.001.\n",
        "3. Train each model separately. Train for 5 epochs, monitor loss, and ensure proper updating of model weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZrn-JHFxlq0"
      },
      "outputs": [],
      "source": [
        "# Training function\n",
        "def train_model(model, train_loader, optimizer, criterion, epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(dml_device), labels.to(dml_device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGoipoJl_iHa"
      },
      "outputs": [],
      "source": [
        "# Train models\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_vgg = optim.Adam(filter(lambda p: p.requires_grad,\n",
        "                                  vgg16.parameters()), lr = 0.001)\n",
        "optimizer_resnet = optim.Adam(filter(lambda p: p.requires_grad,\n",
        "                                     resnet18.parameters()), lr = 0.001)\n",
        "\n",
        "print(\"VGG16:\\n\")\n",
        "train_model(vgg16, train_loader_vgg, optimizer_vgg, loss_fn)\n",
        "\n",
        "print(\"ResNet18:\")\n",
        "train_model(resnet18, train_loader_resnet, optimizer_resnet, loss_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jd_q5mZh_iHa"
      },
      "source": [
        "Compare training behaviours of VGG16 and ResNet18. Which model trains faster and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaryeRKb_iHb"
      },
      "source": [
        "**Written Answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gmoqC3T_iHb"
      },
      "source": [
        "## Question 4: Model Evaluation\n",
        "1. Define a function to calculate the accuracy of each model on the test set.\n",
        "2. Evaluate both models separately.\n",
        "3. Plot confusion matrices for each model using `sklearn.metrics.confusion_matrix` and `ConfusionMatrixDisplay`.\n",
        "4. Interpret results based on model-specific accuracy and confusion matrix insights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t920I1G4_iHb"
      },
      "outputs": [],
      "source": [
        "# Evaluation & confusion matrix\n",
        "# CIFAR-10 class labels\n",
        "cifar10_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "                   'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "def evaluate_model(model, test_loader, loss_fn, dml_device, model_name=\"Model\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    test_labels = np.array([])\n",
        "    test_predictions = np.array([])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(dml_device), labels.to(dml_device)\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            test_labels = np.append(test_labels, labels.cpu().numpy())\n",
        "            test_predictions = np.append(test_predictions, preds.cpu().numpy())\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    test_loss = running_loss / len(test_loader.dataset)\n",
        "    test_acc = running_corrects.float() / len(test_loader.dataset)\n",
        "\n",
        "    print(f\"\\n{model_name} Test Accuracy: {test_acc * 100:.2f}%\")\n",
        "    print(f\"{model_name} Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_true=test_labels, y_pred=test_predictions)\n",
        "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df_cm = pd.DataFrame(\n",
        "        cm_normalized,\n",
        "        index=cifar10_classes,\n",
        "        columns=cifar10_classes,\n",
        "    )\n",
        "\n",
        "    # Plot heatmap\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    heatmap = sns.heatmap(df_cm, annot=True, fmt='.2f', cmap='Blues')\n",
        "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0,\n",
        "                                 ha='right', fontsize=12)\n",
        "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45,\n",
        "                                 ha='right', fontsize=12)\n",
        "    plt.title(f'{model_name} Confusion Matrix')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()\n",
        "\n",
        "    return test_acc.item(), test_loss, cm_normalized\n",
        "\n",
        "# Evaluate VGG16\n",
        "vgg_acc, vgg_loss, vgg_cm = evaluate_model(vgg16_model, test_loader_vgg, loss_fn,\n",
        "                                           dml_device, model_name=\"VGG16\")\n",
        "\n",
        "# Evaluate ResNet18\n",
        "resnet_acc, resnet_loss, resnet_cm = evaluate_model(resnet18_model,\n",
        "                                                    test_loader_resnet,\n",
        "                                                    loss_fn,\n",
        "                                                    dml_device,\n",
        "                                                    model_name=\"ResNet18\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN9VHfl4_iHb"
      },
      "source": [
        "Suggest two additional improvements specifically tailored for the less accurate model. Clearly explain your rationale for each suggestion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkeP75fC_iHb"
      },
      "source": [
        "**Written Answer:**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
