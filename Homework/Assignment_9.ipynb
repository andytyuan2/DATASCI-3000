{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WorgMA_E_iHU"
      },
      "source": [
        "# Assignment 9: CNN with CIFAR-10\n",
        "\n",
        "## Introduction:\n",
        "In this coursework, you will gain practical experience using Convolutional Neural Networks (CNNs) for image classification. Specifically, you'll use two widely recognized pre-trained architectures—VGG16 and ResNet18—to classify images from the CIFAR-10 dataset. CIFAR-10 consists of 60,000 color images (32x32 pixels), evenly divided across 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck.\n",
        "\n",
        "You'll apply transfer learning by adapting these pre-trained models to the CIFAR-10 dataset, train and evaluate both models, compare their performance.\n",
        "\n",
        "## Objectives:\n",
        "- Understand and implement transfer learning.\n",
        "- Train CNN models using pre-trained architectures.\n",
        "- Unfreeze and fine-tune the final convolutional layer of each model.\n",
        "- Evaluate and compare the performance of different CNN models.\n",
        "- Analyze results with a confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "O6kSc0h8_iHX"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms.v2 as v2\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import Subset, DataLoader, random_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PZmKokh4_iHY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is CUDA supported by this system? False\n",
            "CUDA version: None\n"
          ]
        }
      ],
      "source": [
        "# Check if GPU (CUDA) is available, else use CPU\n",
        "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
        "print(f\"CUDA version: {torch.version.cuda}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oD56KzON_iHY"
      },
      "source": [
        "## Question 1: Dataset Setup and Exploration\n",
        "1. Download and load the CIFAR-10 dataset using `torchvision.datasets.CIFAR10`.\n",
        "2. Apply model-specific transformations with data augmentation:\n",
        "   - For VGG16: Use transformations from `VGG16_Weights.DEFAULT.transforms` as a base and apply additional augmentations:\n",
        "       - `AutoAugment` with CIFAR10 policy\n",
        "       - `RandomHorizontalFlip` (50% chance)\n",
        "   - For ResNet18: Use `ResNet18_Weights.DEFAULT.transforms` similarly with the same augmentations applied.\n",
        "3. Use 10% of the training and testing datasets to reduce computation time.\n",
        "4. Define DataLoaders separately for each model for efficient and correct training/testing behavior. Ensure `shuffle = True` for training DataLoaders.\n",
        "5. Visualize a batch of sample images from each model’s DataLoader to confirm that preprocessing and augmentations have been applied correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEoecQEv_iHZ"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "type object 'CIFAR10' has no attribute 'classifier'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# load data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mCIFAR10\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis model is trained for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier\u001b[49m[\u001b[38;5;241m6\u001b[39m]\u001b[38;5;241m.\u001b[39mout_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m classes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mAttributeError\u001b[0m: type object 'CIFAR10' has no attribute 'classifier'"
          ]
        }
      ],
      "source": [
        "# load data\n",
        "model = torchvision.datasets.CIFAR10\n",
        "\n",
        "# Model specific transformations\n",
        "transforms_vgg16 = torchvision.models.VGG16_Weights.DEFAULT.transforms\n",
        "\n",
        "def load_image_data_trainval(data_dir='IntelClassification/seg_train',\n",
        "                            batch_size=32,\n",
        "                            validation_split=0,\n",
        "                            random_seed=42):\n",
        "    \"\"\"\n",
        "    Load an image dataset and splits it into training and validation sets.\n",
        "\n",
        "    Parameters:\n",
        "    - data_dir (str): Path to the data directory.\n",
        "    - batch_size (int): Number of images to be loaded in each batch.\n",
        "    - validation_split (float): The fraction of the dataset to be used as validation set.\n",
        "    - random_seed (int): A seed to ensure reproducibility for the random split.\n",
        "\n",
        "    Returns:\n",
        "    - train_loader (DataLoader): DataLoader for the training set.\n",
        "    - val_loader (DataLoader): DataLoader for the validation set.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define a transformation pipeline\n",
        "    transform = transforms.Compose([\n",
        "        transforms_vgg16(),\n",
        "        v2.AutoAugment(v2.AutoAugmentPolicy.CIFAR10),\n",
        "        v2.RandomHorizontalFlip(p=0.5)\n",
        "        ])\n",
        "\n",
        "    # Create the dataset using ImageFolder\n",
        "    full_dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
        "\n",
        "    # Determine the split sizes\n",
        "    total_size = len(full_dataset)\n",
        "    val_size = int(validation_split * total_size)\n",
        "    train_size = total_size - val_size\n",
        "\n",
        "    # Ensure reproducibility of the split\n",
        "    torch.manual_seed(random_seed)\n",
        "\n",
        "    # Split the dataset\n",
        "    train_dataset, val_dataset = random_split(full_dataset,\n",
        "                                              [train_size, val_size])\n",
        "\n",
        "    # Create the DataLoaders to feed data to the model\n",
        "    train_loader = DataLoader(train_dataset,\n",
        "                              batch_size=batch_size,\n",
        "                              shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset,\n",
        "                            batch_size=batch_size,\n",
        "                            shuffle=False)\n",
        "\n",
        "    return train_loader, val_loader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoA_Dj-D_iHZ"
      },
      "source": [
        "Examine the CIFAR-10 images after applying transformations. Identify two classes you believe are most difficult for the models to distinguish and explain why."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ueehy-J_iHZ"
      },
      "source": [
        "**Written Answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsOORCZH_iHZ"
      },
      "source": [
        "## Question 2: Model Definitions – VGG16 and ResNet18\n",
        "1. Load pre-trained VGG16 and ResNet18 models from torchvision.\n",
        "2. Freeze all convolutional layers initially, then unfreeze the last convolutional block in both models.\n",
        "3. Modify the classifier layers to accommodate CIFAR-10 classification (10 output classes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCy3711T_iHa"
      },
      "outputs": [],
      "source": [
        "# VGG16 setup\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ResNet18 setup\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8IhJC0v1sRo"
      },
      "source": [
        "Explain the concept of transfer learning and its specific advantages when applied to CIFAR-10 classification using models like VGG16 and ResNet18."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjOIzSkW1sRo"
      },
      "source": [
        "**Written Answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ME7xu-z_iHa"
      },
      "source": [
        "## Question 3: Training the Models\n",
        "1. Define the loss function (Cross-Entropy Loss).\n",
        "2. Initialize Adam optimizers for each model with a learning rate of 0.001.\n",
        "3. Train each model separately. Train for 5 epochs, monitor loss, and ensure proper updating of model weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZrn-JHFxlq0"
      },
      "outputs": [],
      "source": [
        "# Training function\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGoipoJl_iHa"
      },
      "outputs": [],
      "source": [
        "# Train models\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jd_q5mZh_iHa"
      },
      "source": [
        "Compare training behaviours of VGG16 and ResNet18. Which model trains faster and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaryeRKb_iHb"
      },
      "source": [
        "**Written Answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gmoqC3T_iHb"
      },
      "source": [
        "## Question 4: Model Evaluation\n",
        "1. Define a function to calculate the accuracy of each model on the test set.\n",
        "2. Evaluate both models separately.\n",
        "3. Plot confusion matrices for each model using `sklearn.metrics.confusion_matrix` and `ConfusionMatrixDisplay`.\n",
        "4. Interpret results based on model-specific accuracy and confusion matrix insights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t920I1G4_iHb"
      },
      "outputs": [],
      "source": [
        "# Evaluation & confusion matrix\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN9VHfl4_iHb"
      },
      "source": [
        "Suggest two additional improvements specifically tailored for the less accurate model. Clearly explain your rationale for each suggestion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkeP75fC_iHb"
      },
      "source": [
        "**Written Answer:**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
