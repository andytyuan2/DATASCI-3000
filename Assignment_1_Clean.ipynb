{"cells":[{"cell_type":"markdown","metadata":{"id":"mEK2QYPrX78R"},"source":["# Assignment 1: Supervised learning, Linear models, and Loss functions\n","\n","In this assignment, you're going to write your own methods to fit a linear model using either an OLS or LAD cost function.  \n","\n","## Data set\n","\n","We will examine some data representing the miles-per-gallon of 398 cars given other variables describing them:\n","\n","1. mpg: continuous. The miles-per-gallon of the car.\n","2. cylinders: multi-valued discrete. Number of cylinders.\n","3. displacement: continuous. Engine displacement of the car.\n","4. horsepower: continuous. Total horsepower of the car.\n","5. weight: continuous. Weight in lbs.\n","6. acceleration: continuous. Acceleration 0-60mph in seconds.\n","9. car name: string (unique for each instance, DO NOT USE)\n","\n","## Follow These Steps Before Submitting\n","Once you are finished, ensure to complete the following steps.\n","\n","1.  Restart your kernel by clicking 'Kernel' > 'Restart & Run All'.\n","\n","2.  Fix any errors which result from this.\n","\n","3.  Repeat steps 1. and 2. until your notebook runs without errors.\n","\n","4.  Submit your completed notebook to OWL by the deadline.\n","\n","\n","## Preliminaries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aBu-equFX78Y"},"outputs":[],"source":["# Import all the necessary packages:\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import scipy.stats as ss\n","import scipy.optimize as so\n","from sklearn import linear_model\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rBv9WDghTVHx"},"outputs":[],"source":["# Uncomment if using Google Colab or Kaggle Kernels.\n","# Imports the data using gdown.\n","# !gdown https://drive.google.com/uc?id=1PtY3ne37XA8Jk_cAf0Cd7JSRvEU8KDbp"]},{"cell_type":"markdown","metadata":{"id":"m8CtqKgpX78f"},"source":["\n","## Part 1\n","### Question 1.1:\n","\n","\n","Read the `car_data.csv` file as a `pandas.DataFrame` and show its descriptive statistics.  Investigate the relationship between the cars' weight and their mpg by plotting a scatter plot of the `weight` (x axis) and `mpg` columns (y axis). Add an `alpha` (transparency of the plotted dots) in case some data are overlapping. Remember to label your axes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WdFNvFsRUdx9"},"outputs":[],"source":["# YOUR CODE HERE"]},{"cell_type":"markdown","metadata":{"id":"XUVK0ZGmTAcE"},"source":["**Written answer: What do you see here? Discuss your findings**"]},{"cell_type":"markdown","metadata":{"id":"aLTkjzp2X78w"},"source":["### Question 1.2: point\n","\n","Recall that the linear model, we obtain predictions by computing\n","\n","$$ \\hat{\\mathbf{y}} = \\mathbf{X} \\hat{\\beta} $$\n","\n","Here, $\\mathbf{X}$ is a design matrix which includes a column of ones, $\\hat{\\beta}$ are coefficients, and $\\hat{\\mathbf{y}}$ are outcomes.  Write a function `linearModelPredict` to compute linear model predictions given data and a coefficient vector.  The function should take as it's arguments a 1d-array of coefficients `b` and the design matrix `X` as a 2d-array and return linear model predictions `yp`.\n","\n","Test the function by setting\n","\n","```\n","X = np.array([[1,0],[1,-1],[1,2]])\n","b = np.array([0.1,0.3])\n","```\n","\n","Call your function using these values.\n","\n","Report $\\hat{\\mathbf{y}}$. Print the dimensionality of the numpy-array that you get.\n","\n","Hint:  Read the documentation for `np.dot` or the `@` operator in `numpy`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"So7kD_OPVQNI"},"outputs":[],"source":["# Your code here."]},{"cell_type":"markdown","metadata":{"id":"CrZokVidX787"},"source":["### Question 1.3:\n","\n","Write a function `linearModelMSE` which computes and returns the mean squared error parameterized by $\\beta$, as well as the gradient of the loss.  The function should take as its first argument a 1D-array `beta` of coefficients for the linear model, as its second argument the design matrix `X` as a 2D-array, and as its third argument a 1D-array `y` of observed outcomes. Recall that:\n","\n","$$\n","MSE(y_i, \\hat{y_i}) = \\frac{1}{|I|} \\sum_i (y_i - \\hat{y_i})^2\n","$$\n","$$\n","\\nabla MSE(y, \\hat{y}) = -\\frac{2}{|I|} \\left[(y-\\hat{y}) \\cdot X\\right]\n","$$\n","\n","Test the function with the values\n","\n","```\n","X = np.array([[1,0],[1,-1],[1,2]])\n","b = np.array([0.1,0.3])\n","y = np.array([0,0.4,2])\n","```\n","\n","Report the loss and the gradient.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IHuS9PJJVZiW"},"outputs":[],"source":["# Your code here."]},{"cell_type":"markdown","metadata":{"id":"O7tEGnLsVb4L"},"source":["**Written answer**: To minimize the loss, do you need increase or decrease the value of the parameters?"]},{"cell_type":"markdown","metadata":{"id":"gT7yoJLIt9Xs"},"source":["**Your answer here.**"]},{"cell_type":"markdown","metadata":{"id":"zpfl2A86X79D"},"source":["### Question 1.4:\n","\n","Now that you've implemented a loss function in question 1.3, it is now time to minimize it!\n","\n","Write a function `linearModelFit` to fit a linear model.  The function should take as its first argument the design matrix `X` as a 2D-array, as its second argument a 1D-array `y` of outcomes, and as its third argument a function  `lossfcn` which returns as a tuple the value of the loss, as well as the gradient of the loss. As a result, it should return the estimated betas and the $R^2$. Pass the argument `jac=True` to the `miminize` function so that it uses your gradient.\n","\n","Test the function with the values:\n","```\n","X = np.array([[1,0],[1,-1],[1,2]])\n","y = np.array([0,0.4,2])\n","```\n","\n","Report the best parameters and the fitted $R^2$.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HfGGnSoRt7us"},"outputs":[],"source":["# Your code here"]},{"cell_type":"markdown","metadata":{"id":"CJ2ZergqX79L"},"source":["### Question 1.5:\n","\n","Use the above functions to fit your model to the car data. Use the MPG as the target (y) variable and only the weight variable as the independent (x). Fit the model with a constant. Then use your model and the fitted parameters to make predictions along a grid of equally spaced weights within the original range of the weight variable.  \n","\n","Plot the data and add a line for the predicted values. You can get these by generating a new X-matrix with 100 equally space weights (using for example [```np.linspace```](https://numpy.org/doc/stable/reference/generated/numpy.linspace.html)). Also report the $R^2$ value for the fit. You can do this by either printing out the $R^2$ of the fit or putting it on your plot via the `annotate` function in matplotlib.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ije0Hki9t44-"},"outputs":[],"source":["# Your code here"]},{"cell_type":"markdown","metadata":{"id":"QxNhhYIlavkb"},"source":["**Your answer here**"]},{"cell_type":"markdown","metadata":{"id":"4OS_X9KXavkc"},"source":["### Question 1.6:\n","\n","Now use sklearn's `linear_model` to fit the model with all the available data. Plot the data and add a line for the predicted values as you did in the previous question. Also report the $R^2$ value for the fit.\n","\n","**Written answer: How much do you gain by having more variables?**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GG4OcXH8avkd"},"outputs":[],"source":["# Your code here"]},{"cell_type":"markdown","metadata":{"id":"EAgeZwMsavkd"},"source":["**Your answer here.**"]},{"cell_type":"markdown","metadata":{"id":"A3emHgAcX79R"},"source":["## Part 2: LAD Regression\n","\n","### Question 2.1:\n","\n","In the previous section, we worked with the squared loss.  Now, we'll implement a linear model with least absolute deviation loss $LAD(y_i, \\hat{y_i})$.\n","\n","$$\n","LAD(y_i, \\hat{y_i}) = \\frac{1}{|I|}\\sum_i |y_i - \\hat{y_i}|\n","$$\n","\n","where $y_i$ is the true label of sample $i \\in I$, $\\hat{y_i}$ is the prediction, $I$ is the sample set, and $|I|$ is the number of cases in the sample. The gradient of the function is:\n","\n","$$\n","\\nabla LAD(y, \\hat{y}) = - \\frac{ sign(y_i - \\hat{y_i}) \\cdot X}{|I|}\n","$$\n","\n","with `sign` the sign function. Note this function is undefined at 0.\n","\n","Write a function `linearModelLossLAD` which computes the least absolute deviation loss function for a linear model parameterized by $\\beta$, as well as the gradient of the loss, following the same structured as the previous part.\n","\n","Test the function with the values\n","\n","```\n","X = np.array([[1,0],[1,-1],[1,2]])\n","b = np.array([0.1,0.3])\n","y = np.array([0,0.4,2])\n","```\n","\n","Report the loss and the gradient."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K-Fz6flkuD0j"},"outputs":[],"source":["# Your code here"]},{"cell_type":"markdown","metadata":{"id":"MTx_xIR5X79V"},"source":["### Question 2.2:\n","\n","\n","Use the above functions to fit your LAD model using the weight variable as input, to predict the mpg. Use your model to make predictions along a grid of 100 equally spaced car weights.  Once fit, add the fitted line to the scatter plot as in question 1.5.  Also report the $R^2$-value.\n","\n","**Written answer**: What is the difference in the fit obtained with an $L_1$ as compared to the $L_2$ cost function? How do their $R^2$ values compare? Why?  \n","\n","Note: If you receive an error from the optimizer, it may be because the loss function for the LAD model is not differentiable at its minimum.  This will lead to some gradient-based optimizers to fail to converge.  If this happens to you then pass `method=\"Powell\"` to `scipy.optimize.minimize`.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WjzoFgyOuFPc"},"outputs":[],"source":["# Your code here"]},{"cell_type":"markdown","metadata":{"id":"Z0tRMvEiuGJe"},"source":["**Your answer here.**"]},{"cell_type":"markdown","metadata":{"id":"4Tza7fD4X79a"},"source":["### Question 2.3:\n","\n","Now we will use all data for the fit. Fit an LAD model to the car data (excluding the name) with the `linear_model` module from the `sklearn` package by using the [`QuantileRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.QuantileRegressor.html#sklearn.linear_model.QuantileRegressor) class that implements a [pinball loss](https://en.wikipedia.org/wiki/Quantile_regression), a more general case of the [`mean_absolute_error`](https://scikit-learn.org/1.5/modules/generated/sklearn.metrics.mean_absolute_error.html) loss. To get an MAD regression, set the parameters `alpha=0` and `quantile=0.5` in the `QuantileRegressor` call.\n","\n","In no more than two sentences, comment on the $R^2$ values for both the OLS and MAD regressions. Use the `sklearn` models for this analysis. Are they similar? Make a scatterplot of the sklearn's OLS and MAD predictions."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l7xLq3wPuJBf"},"outputs":[],"source":["# Your code here"]},{"cell_type":"markdown","metadata":{"id":"3X_4N0aouLD5"},"source":["**Your answer here.**"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1"}},"nbformat":4,"nbformat_minor":0}